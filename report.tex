\documentclass[english,10pt,twocolumn]{article}

\usepackage{times}
\usepackage{fullpage}
\usepackage{babel}
\usepackage{graphicx}


\begin{document}

\title{Keyvee: A Unikernel Key-Value Store}
\author{Nate Brennand, Gudbergur Erlendsson, Mishail Tupas}
\date{May 6th, 2015}
\maketitle
\thispagestyle{empty}


\begin{abstract}
Traditional web infrastructure models consist of a cluster of heavyweight full stack virtual machines usually running a variant of Linux.
This provides a simple consistent platform for developers to write their applications against but running a full stack machine on top of a hypervisor has downsides, for example a lot of resource overhead.
Key-value datastores are a common component of web infrastructure.
Unikernels are specialized OS kernels that are written in a high-level language and act as individual software components.
Unikernels allow restructuring of entire virtual machines into more modular components that are flexible, secure, and reusable in the style of a library operating systems. Applications can be developed and then compiled into unikernels using a toolchain, such as MirageOS for example, and can be deployed directly on top of a Xen hypervisor.
We've designed a Mirage OS\cite{mirage} unikernel implementation of the popular Redis\cite{redis} in-memory key-value store that allows fast creation and deployment of the datastore as well as ease scaling up the allocated resources.
We describe the advantages and disadvantages that come with such a system.
We highlight the performance characteristics of this new approach in comparison to Redis.

Preliminary results showed lower-than-expected performance.
We expect with more profiling and testing we can identify the hotspots in our codebase and garner better performance from the Keyvee implementation.
\end{abstract}


\section{Introduction}
In-memory key-value datastores like Redis are used in a wide variety of applications for ease of use and high throughput.
While these kind of databases are known for their great performance, research has shown that networked applications striving for low latency, such as Redis, are actually subjected to a high amount of overhead from utilizing Linux's networking stack.\cite{arrakis}
This issue is amplified by the lack of stability in allocated resources when running on Linux itself which is prone to performance dips when the resource scheduler is not coordinated. 

While Redis has some tricks to minimize latency and roundtrips, like pipelining for example, we believe that the approach of moving the key-value datastore to a unikernel implementation will yield greater and more reliable performance.
A unikernel is a specialized application capable of running directly on top of bare-metal or a hypervisor without a host operating system, eliminating layers to achieve better performance.
The unikernel approach mitigates many of the performance issues plaguing Redis that cannot be resolved at the application level.
We build on top of the MirageOS\cite{mirage}, OCaml based library operating system that constructs unikernels.
MirageOS provides correctness due to the strongly-typed nature of OCaml which yields very reliable code.

We measure the performance characteristics of Redis in multiple situations to yield a direct comparison to our implementation, Keyvee.
Keyvee speaks the Redis Serialization Protocol\cite{redis-protocol}, RESP, which makes Keyvee a drop in replacement for Redis in any deployment utilizing the Xen Hypervisor.
We hope this compatibility will allow Keyvee to help establish unikernels as a viable piece of web application infrastructure.

\subsection{Related Work}

In addition to MirageOS, there are several other different ongoing efforts to implement unikernels and achieve similar results.
HaLVM\cite{halvm} and LING\cite{ling} are examples of alternatives to MirageOS, using Haskell and Erlang respectively as the basis of their unikernel implementation.
Each of the unikernel implementations HaLVM, LING and Mirage, share the trait that you are limited to one functional language exclusively and compile into an image to run on top of the Xen hypervisor.
MirageOS and LING focuses on performance and predictability while HalVM focuses more on elegant compositional semantics using Haskell, according to the authors\cite{tripreport}.
Low level libraries are being implemented for the platforms in their native code, so while the work is ongoing the level of support varies.
MirageOS for examples uses OCaml-DNS, Mirage-TCPIP and other libraries. It also has a relatively advanced TLS library (OCaml-TLS) and better support for encrypted traffic then the other two library operating systems mentioned earlier. There

OSv\cite{osv} is another variant to the special-purpose operating system using the library OS paradigm, mostly based on code from BSD.
In OSv everything runs in the kernel space and it's built to run as guest on top of a virtual machine.
However, it supports Linux ABI, and contains necessary functionality to run Java and POSIX applications which allows OSv to run some existing codebases and get some of the performance benefit Mirage enjoys, but not increased security.
To get zero-copy I/O specific non-POSIX OSv API's need to be used.
Mirage however does not focus on support for legacy applications but rather focuses on a toolkit to assemble new unikernel applications without specific domain knowledge in kernel programming.

Arrakis\cite{arrakis}, SPIN\cite{spin} and Exokernel\cite{exokernel} all reduce shared kernel components and allow each application to have customized operating system management, achieving some of the increased performance benefit of MirageOS without tying you to one language runtime.
Arrakis in particular benefits from increased support for virtualization in new hardware, which allows it to effectively run all applications in kernel space and achieve separation using hardware instructions, similar to how MirageOS achieves separation through Xen.



\section{Background}



\subsection{Xen Hypervisor}

Xen is an open-source tool that originated as a research project at the University of Cambridge to allow a host to simultaneously host many virtual machines on the same physical host.
Xen usually starts from a bootloader, boots a hypervisor and loads a host operating system into dom0, which is the most privileged domain inside Xen and the only one with direct access to the hardware. All the other virtual machines are managed through the dom0 operating system. The Xen hypervisor is however the lowest layer of the system, and it's responsibilities include memory management, CPU scheduling etc.
Xen allows performant configurations of 100's of virtual machines running in parallel on virtualized resources.
Standard operating systems can be run on Xen with minimal changes to the codebase.
For applications running on a host, such as Linux, Xen has no impact on the implementation because all of the integrations are completed at the OS layer which interfaces with Xen hypervisor.
This however means that there is an extra layer between the hardware and the applications running in a hypervised environment, and eliminating this layer is one of the goals of MirageOS and our project.


\subsection{Redis}

Redis is a type of database called data structure server and is the most popular key-value store in industry\cite{dbengines}.
Redis maps keys to various types of values, including strings (supported by Keyvee) as well as lists of strings, sets of strings, hash tables etc.
Its working set and all of its data is in-memory at all times, allowing for fast data storage and retrieval but there is also optional durability using append-only log files.
Redis is widely used and has various applications in server infrastructure, including caching, inter-server communication, queues etc.
It has support for master-slave replication, and allows slaves to be masters to other slaves, enabling Redis to implement single-rooted replication tree.
Redis also has support for clustering as of version 3.0, using a TODO
When durability is not needed, Redis is very performant, although according to tests it has been shown to spend upward of 84\% of it's processing in kernel space, meaning there is space to improve its performance by increasing the performance of the network stack \cite{latency}.


\subsection{MirageOS}

MirageOS is an OCaml-based library operating system that originated from the Xen Project. It allows you to compile applications directly to a Xen hypervisor image, meaning you can run said applications directly on top of a Xen hypervisor without an intermediary operating system.
This approach yields several performance, implementation and security benefits.
Mirage applications are entirely type-safe due to the strong typing of OCaml and the projects effort to reimplemented frameworks such as TCP/IP and SSL to have end-to-end type safety in the MirageOS stack. They also have a very compact size due to the lack of structural libraries that must be included.
With the elimination of an operating system interface layer, Mirage applications achieve top-notch performance as there is no additional layer in the IO pipeline or scheduler to delay the application's execution.

\begin{figure}[ht]
  \centering
  \caption{MirageOS architecture}
  \includegraphics[width=0.5\textwidth]{images/design}
\end{figure}

Thanks to its simple runtime, OCaml, an expressive functional systems programming language, was a good fit for the Mirage project, and was used to re\-implement the runtime in an image that would run on Xen.
The strictness of OCaml's type system ensures that programs are respect with regard to variable data types prior to compilation, because of this strictness the executable is able to shed all type checking which yields fast native code with performance comparable to C.

As highlighted in Figure 1, unikernels have a greatly reduced overhead when accessing resources relative to an application running on Linux.
This approach brings some great benefits like zero-copy IO and no scheduler-induced delay in response.
These performance improvements are important in high throughput and low latency applications like key-value datastores.
However, this approach does have downfalls such as Mirage's limit to a single virtual machine per core; this limitation means that certain applications that require access to multiple physical threads will not fit the Mirage programming model.
For applications that do not need multiple physical threads but need asynchronous IO, Mirage has a lightweight cooperative threading, LWT, library that provides simple constructs for asynchronous code.

Simple experiments with Mirage have proven that competitive performance to native C applications is not difficult to achieve.
For example, a Mirage DNS server implementation outperformed the standard Bind9 and NSD servers by 14\% in raw throughput in testing.
This indicates that for the right workload, Mirage is an attractive choice that should be evaluated.

In addition to the performance benefits, unikernels are inherently more secure than a standard operating system.
The smaller the attack surface area, the more difficult it is to compromise an application.
In addition, by reimplementing TCP/IP, SSL and more in OCaml, the MirageOS project aims to make memory safety end-to-end from application code to the lowest level.
When a Mirage image is compiled, only the imported libraries are included which means that only the necessary ports and protocols are exposed.
This aspect, combined with the type-safety OCaml provides eliminates entire classes of security vulnerabilities in Mirage applications.





\section{Design and Implementation}
For Keyvee we have the following goals:
\begin{itemize}
  \item Implement subset of Redis functionality in OCaml on top of the MirageOS toolchain.
  \item Make Keyvee as compatible to Redis as possible and hopefully a drop-in replacement for most purposes.
  \item Implement RESP, Redis's protocol specification, to allow interoperability with existing tools and libraries.
\end{itemize}

Here in this section we will talk about our implementation of Keyvee and how we try to accomplish these goals.

\subsection{Overview}

\begin{figure}[ht]
  \centering
  \caption{Supported commands}
  \includegraphics[width=0.5\textwidth]{images/commands_new}
\end{figure}

Keyvee is implemented on top of the MirageOS toolchain using OCaml.
Currently, we support the GET, SET, DEL, PING, MSET and MGET commands.
All data is stored in-memory, similar to Redis.
We have an internal module implementation built on top of OCaml's Hashtbl module, which stores our keys and associated data in an efficient lookup table.
We use a hash table with a seeded hash function, using a seed randomly chosen at hash table creation time.
This means the hash function is randomly selected among 230 different hash functions with different collision patterns which helps stop denial-of-service attacks where attackers can send input crafted to create collisions, slowing our application to a halt.

We use MirageOS's low level TCP/IP network stack implemented in pure OCaml.
Because memory layout in Mirage is used to distinguish I/O pages, the OCaml garbage collector needs to scan less to be as effective as in a full stack OS, which let's the network stack perform predictably.
Predictable performance, as well as support for zero-copy I/O makes Mirage's network stack more performant than traditional full stack OS.
The network stack then hands off the raw data to our parse functions, which parse the data using string operations.
The parse functions fully support well formed queries for our supported functions, but lack some verification steps and will not respond to badly formed queries.
After the parse phase, the data is handed off to the Hashtbl module which responds with data or writes data.
The response is then written to the client in RESP compatible format.

Mirage uses the Lwt, cooperative threading library, extensively and every request is wrapped in a lightweight cooperative thread. Leveraging Mirage and OCaml guarantees type safety in both our application as well as in the implementations of frameworks underlying the application such as the TCP/IP stack, enhancing the security of our implementation.

\subsection{LWT}

TODO Talk about LWT

\subsection{Redis implementation}

As Redis is a full featured and working database implementation it goes through a lot of steps that Keyvee does not. It starts by initializing a server state structure, which is where it stores configuration information such as the port it is running on, database files, replication, sort parameters etc. Redis is well written and one interesting things it does is set up number of shared objects or common Redis objects that are required by many different aspects of the system, one of them being a pool of shared integers which helps Redis being very efficient with memory. Redis then creates a event loop, using epoll on Linux and kqueue on BSD and falls back to select if those are not available. This is what makes Redis so responsive and allows it to be single threaded but still serve thousands of clients simultaneously, and is comparable to what LWT and the LWT event engine does for KeyVee. After setting up the event loop, Redis further initalizes databases (it has support for multiple databases), TCP listening socket, sets up a server cron function which is called every 100 milliseconds and handles misc administrative tasks and finally registers a connection handler with the event loop and opens an append-only file if configured to do so. Redis accepts connections in the event loop using standard POSIX methods, and as RESP is a ASCII based protocol it parses strings to process the commands similarily to how Keyvee does this, albeit it does it in a very efficient manner. After parsing the command string, the command is looked up in the internal command table and it's executed. Write commands such as SET make the server have dirty data so the server is marked as having pages in memory that have changed. This is then used during the automatic save process and append-only file writing process. TODO: Clean up

\subsection{Benefits}

The benefits that can be gained from a MirageOS implementation of Redis are mainly performance and security benefits.

\subsubsection{Performance}

Although our current test implementation did not exceed Redis's implementation under heavy load, theoretically the MirageOS implementation should be more performant by making the stack smaller and eliminating the OS networking layer. We are certain that with more optimization work KeyVee would become more performant than Redis with equal functionality.

\subsubsection{Security)

    There are two security aspects of MirageOS that are pertinant to our Keyvee implementation. By only compiling Keyvee into a OS image, a lot of extra services and weak points in traditional OS's are not run, and so with a smaller attack surface certain kinds of vulnerabilities are eliminated. In addition to minimizing the attack surface, MirageOS applications are end-to-end memory safe. That means from the TCP/IP stack, up to SSL and the application code, everything is compiled using a memory-safe language which gives us guarantees that Keyvee is memory safe. While Redis is well written and has good test coverage, it cannot be guaranteed to be memory-safe like Keyvee, being written purely in C. The recommendation for deployment of Redis is to put it behind a firewall, which is both because of lack of user access control (anyone can for example issue FLUSHDB and remove all data from server) but another concern is the lack of memory safety. This means Redis is vulnerable to buffer overflow and out of bounds errors for example which have been the main sources of vulnerabilities in server software, latest big example being the Heartbleed bug. Meanwhile, Keyvee is completely memory safe and with addition of user access controls could be safe to be exposed on the internet, which opens it up to a whole host of applications that Redis could only handle by having a server as a intermediary. For example, a mobile client could connect directly to Keyvee for data that needs no server processing instead of going through a intermediary server.

TODO: CLEAN UP

\subsection{Development process}

We use distributed version control system Git and Github to track changes to our codebase.
Travis Continuous Integration is then used to build our codebase when changes are made and check for any errors.
It is possible to build a Unix binary using the Mirage toolchain, which we use extensively when developing our code before it is deployed and tested on the Xen server.

The MirageOS documentation leaves a lot to be desired and many times we needed to go looking into MirageOS's implementation it self.
In addition, some OCaml modules do not work with the toolchain and there is scarcity of open source code built with it.
Especially as it is the early days there is not a lot of community support surrounding Mirage.


\section{Evaluation}

We performed all of our evaluations on a dedicated 8-core HP ProLiant rack server with 16 GB RAM available.
Our Xen hypervisor installation is coordinated by a Ubuntu Server 14.04 host that serves as the management domain to manage the other hosts running on the Hypervisor.
The Mirage installation was modified to use Redis's communication protocols so that we could use the same benchmark for all test setups. The benchmark was run using 50 parallel clients sending a 3-byte payload.
The Redis setups were given ten thousands requests as part of their benchmark, while the Mirage setups on Xen were given five hundred, one thousand, or ten thousand requests.


\subsection{Running Mirage}

When a MirageOS unikernel is configured in Xen mode, both the unikernel image and the configuration file are generated.
With these, a unikernel can be easily launched using the xl Xen management tool.
Due to the small size of the image, this is a quick process where the Mirage image configures itself when started by xl.


\subsection{Network Overhead}

On examining the throughput and the completion times for requests between running the benchmark between two hosts, we found that there was a significant overhead imposed by network communications. For SET operations there was an increase of 42\% in execution time and GET operations saw a similar 43\% increase in execution time.
The benchmark results for the MirageOS installation were found to have throughputs an order of magnitude lower than expected.
Upon further testing and examination of code, it found that that the Mirage systems were not properly handling multiple simultaneous clients, resulting in a very low throughput which was noticed in further tests.


\subsection{Mirage - UNIX}

Three different benchmarks setups were tested, making either five hundred, one thousand, or ten thousand total requests.
Similarly to the tests run on the Mirage installations that were on top of Xen, the throughput was also an order of magnitude lower when compared to Redis. 
Strangely, the Unix-based setups did much better for the five hundred and one thousand request trials, but did extremely poorly for the ten thousand request setup.

\subsection{Throughput Performance}

\begin{figure*}[ht]
  \centering
  \caption{Average Throughputs}
  \includegraphics[width=1.0\textwidth]{images/throughput}
\end{figure*}

\begin{table}[h]
\begin{tabular}{lll}
Average Throughput & SET Operation & GET Operation \\
Native & 37766.142 & 37792.576 \\
Host-to-Host & 26571.512 & 26348.028 \\
Mirage on Xen & 2188.18 & 2222.22 \\
Unix (500) & 3401.36 & 3787.88 \\
Unix (1000) & 3344.48 & 2024.29 \\
Unix (10000) & 580.55 & 338.26
\end{tabular}
\caption{Average throughputs (requests per second)}
\label{my-label}
\end{table}

Overall, the Mirage systems showed markedly worse throughput performance, at a staggering order of magnitude lower than the baseline Redis benchmarks.
Corrections to the Keyvee implementation are underway so that a fair benchmark comparison can be made and a provide a more representative view.

\section{Conclusion}
In this paper we described the implementation and evaluation of our unikernel key-value store, Keyvee.
Our efforts are concentrated around implementing a subset of Redis's functionality using OCaml and the MirageOS toolchain.
We then evaluated our implementation and compared it with Redis using Redis's benchmarking tool.
Initial results revealed that, even when taking into account networking overhead, our unikernel implementation performed extremely poorly in both a Xen enviroment and a Unix installed environment.
The main source of the low throughput was identified as an issue with handling the TCP clients used for benchmarking, resulting in a loss of parallelization.
A fix is currently being developed and will be tested shortly to provide a better image of Keyvee's performance.


\section{Acknowledgements}
We thank the kind souls in the \#Mirage IRC chatroom for their relentless patience.
Their assistance was crucial in learning how to use Mirage's utilities and leverage the provided standard library.



\bibliographystyle{abbrv}
\bibliography{bibliography}


\end{document}




\documentclass[english,10pt,twocolumn]{article}

\usepackage{times}
\usepackage{fullpage}
\usepackage{babel}
\usepackage{graphicx}


\begin{document}

\title{A Unikernel Key-Value Store}
\author{Nate Brennand, Gudbergur Erlendsson, Mishail Tupas}
\date{}
\maketitle
\thispagestyle{empty}


\begin{abstract}
Traditional web infrastructure models consist of a cluster of heavyweight full stack virtual machines usually running a variant of Linux.
This provides a simple consistent platform for developers to write their applications against but it has many downfalls in the resource overhead of running virtual machines.
Key-value datastores are a common component of web insfrastructure.
We've designed a Mirage OS\cite{mirage} unikernel implementation of the popular Redis\cite{redis} in-memory key-value store that allows fast creation and deployment of the datastore as well as ease scaling up the allocated resources.
Applications developed with MirageOS can be deployed directly on the Xen hypervisor.
We describe the advantages and disadvantages that come with such a system.
We highlight the performance characteristics of this new approach in comparison to Redis.

Preliminary results show comparable performance.
We expect with more profiling we can identify the hotspots in our codebase and garner better performance from the Kayvee implementation.
\end{abstract}


\section{Introduction}
In-memory key-value datastores are used in a wide variety of applications for ease of use and the high throughput.
While these applications are known for their great performance, research has shown that networked applications striving for low latency, such as Redis, are actually subjected to a high amount of overhead from utilizing Linux's networking stack.\cite{arrakis}
This issue is amplified by the lack of stability in allocated resources when running on Linux itself which is prone to performance dips when the resource scheduler is not coordinated.

We believe that the approach of moving the key-value datastore to a unikernel implementation will yield greater and more reliable performance.
A unikernel is a specialzed application capable of running directly on top of bare-metal or a hypervisor without a host operating system.
The unikernel approach lacks many of the performance issues plaguing Redis that cannot be resolved at the application level.
We build on top of the Mirage OS\cite{mirage}, an OCaml based library operating system.
MirageOS provides correctness due to the strongly-typed nature of OCaml, this yields very reliable code.

We measure the performance characteristics of Redis in multiple situations: networked and on-host, to yield a direct comparison to our implementation, Kayvee.
Kayvee speaks the Redis Serialization Protocol\cite{redis-protocol}, RESP, which makes Kayvee a drop in replacement for Redis in any deployment utilizing the Xen Hypervisor.
We hope this compatibility will allow Kayvee to help establish unikernels as a viable piece of web application infrastructure.


\section{Background}



\subsection{Xen Hypervisor}

The Xen hypervisor is a tool to allow a host to simultaneously host many virtual machines on the same physical host.
Xen allows performant configurations of 100's of virtual machines running in parallel on virtualized resources.
Standard operating systems can be run on Xen with minimal changes to the codebase.
For applications running on a host, such as Linux, Xen has no impact on the implementation because all of the integrations are completed at the OS layer.


\subsection{Mirage OS}


\begin{figure}[ht]
  \centering
  \caption{Mirage OS architecture}
  \includegraphics[width=0.5\textwidth]{images/design}
\end{figure}

The unikernel concept was first outlined

Today there are server operating systems developed for cloud computing that based on the concept of unikernels. MirageOS is a library operating system written in Ocaml that is commonly used for constructing unikernels.

(What are key-value stores for?)

Redis, short for Remote Dictionary server, is a key-value store software that is commonly used in distributed systems on virtualized operating systems.
It features ().
However, this software is generally run atop a full operating system installation, which incurs a certain degree of overhead as discussed previously.
While the OSv operating system can support Redis, it does not function optimally.



\subsection{Related Work}

HaLVM\cite{halvm} and LING\cite{ling} are both alternatives to Mirage OS, using Haskell and Erlang respectively as the basis of their unikernel efforts.
Each of the unikernel implementations: HaLVM, LING and Mirage, share the trait that you are limited to one functional language exclusively and compile into an image to run on top of the Xen hypervisor.
Mirage OS and LING focuses on performance and predictability while HalVM focuses more on elegant compositional semantics using Haskell, according to the authors\cite{tripreport}.
Low level libraries are being implemented for the platforms in their native code, so while the work is ongoing the level of support varies.
Mirage OS for examples uses OCaml-DNS, Mirage-TCPIP and other libraries. It also has a relatively advanced TLS library (OCaml-TLS) and better support for encrypted traffic then the other two library operating systems mentioned earlier.

OSv\cite{osv} is another variant to the special-purpose operating system using the library OS paradigm, mostly based on code from BSD.
In OSv everything runs in the kernel space and it's built to run as guest on top of a virtual machine.
However, it support Linux ABI, and contains necessary functionality to run Java and POSIX applications which allows OSv to run some existing codebases and get some of the performance benefit Mirage enjoys.
To get zero-copy I/O specific non-POSIX OSv API's need to be used.
Mirage however focuses on a toolkit to assemble new unikernel application without specific domain knowledge in kernel programming for example.

Arrakis\cite{arrakis}, SPIN\cite{spin} and Exokernel\cite{exokernel} all reduce shared kernel components and allow each application to have customized operating system management, achieving some of the increased performance benefit of Mirage OS without tying you to one language runtime.
Arrakis in particular benefits from increased support for virtualization in new hardware, which allows it to effectively run all applications in kernel space and achieve seperation using hardware instructions, similar to how Mirage OS achieves seperation through Xen.




\section{Design and Implementation}
For Keyvee we have the following goals:
\begin{itemize}
  \item Implement subset of Redis functionality in OCaml on top of the Mirage OS toolchain
  \item Make Keyvee's as compatible to Redis as possible.
  \item Implement RESP, Redis's protocol specification, to allow interoperability with existing tools and libraries.
\end{itemize}

Here in this section we will talk about our implementation of Keyvee and how we try to accomplish these goals.

\subsection{Overview}

\begin{figure}[ht]
  \centering
  \caption{Supported commands}
  \includegraphics[width=0.5\textwidth]{images/commands}
\end{figure}

Keyvee is implemented on top of the Mirage OS toolchain using OCaml.
Currently, we support the GET, SET and DEL commands.
All data is stored in-memory, similar to Redis.
We have an internal module implementation built on top of OCaml's Hashtbl module, which stores our keys and associated data in an efficient lookup table.
We use a hash table with a seeded hash function, using a seed randomly chosen at hash table creation time.
This means the hash function is randomly selected among 230 different hash functions with different collision patterns which helps stop denial-of-service attacks where attackers can send input crafted to create collisions, slowing our application to a halt.

We use MirageOS's low level TCP/IP network stack implemented in pure OCaml.
Because memory layout in Mirage is used to distinguish I/O pages, the OCaml garbage collector needs to scan less to be as effective as in a full stack OS, which let's the network stack perform predictably.
Predictable performance, as well as support for zero-copy I/O makes Mirage's network stack performant.
The stack then hands off the raw data to our parse functions, which parse the data using string operations.
The parse functions fully support well formed queries for our supported functions, but lack some verification steps and will not respond to badly formed queries.
After the parse phase, the data is handed off to the Hashtbl module which responds with data or writes data.
The response is then written to the client in RESP compatible format.

Mirage uses the Lwt, cooperative threading library, extensively and every request is wrapped in a lightweight cooperative thread. Leveraging Mirage and OCaml guarantees type safety in both our application as well as in the implementations of frameworks underlying the application such as the TCP/IP stack, enhancing the security of our implementation.


\subsection{Development process}

We use distributed version control system Git and Github to track changes to our codebase.
Travis Continuous Integration is then used to build our codebase when changes are made and check for any errors.
It is possible to build a Unix binary using the Mirage toolchain, which we use extensively when developing our code before it is deployed and tested on the Xen server.

The Mirage OS documentation leaves a lot to be desired and a lot of times we needed to go looking into Mirage OS's implementation it self.
In addition, some OCaml modules do not work with the toolchain and there is scarcity of open source code built with it.
Especially as it is the early days there is not a lot of community support surrounding Mirage.


\section{Evaluation}

We performed all of our evaulations on a dedicated 8\-core HP ProLiant rack server with 16 GB RAM available.
Our Xen hypervisor installation is coordinated by a Ubuntu Server 14.04 host that serves as the management domain to manage the other hosts running on the Hypervisor.
The Mirage installation was modified to use Redis's communication protocols so that we could use the same benchmark for all test setups. The benchmark was run using 50 parallel clients sending a 3-byte payload.
The Redis setups were given ten thousands requests as part of their benchmark, while the Mirage setups on Xen were given five hundred, one thousand, or ten thousand requests.


\subsection{Running Mirage}

When a Mirage OS unikernel is configured in Xen mode, both the unikernel image and the configuration file are generated.
With these, a unikernel can be easily launched using the xl Xen management tool.
Due to the small size of the image, this is a quick process where the Mirage image configures itself when started by xl.


\subsection{Network Overhead}

On examining the throughput and the completion times for requests between running the benchmark between two hosts, we found that there was a significant overhead imposed by network communications. For SET operations there was an increase of 42\% in execution time and GET operations saw a similar 43\% increase in execution time.
The benchmark results for the Mirage OS installation were found to have throughputs an order of magnitude lower than expected.
Upon further testing and examination of code, it found that that the Mirage systems were not properly handling multiple simultaneous clients, resulting in a very low throughput which was noticed in further tests.


\subsection{Mirage \- UNIX}

Three different benchmarks setups were tested, making either five hundred, one thousand, or ten thousand total requests.
Similarly to the tests run on the Mirage installations that were on top of Xen, the throughput was also an order of magnitude lower when compared to Redis. 
Strangely, the Unix-based setups did much better for the five hundred and one thousand request trials, but did extremely poorly for the ten thousand request setup.

\subsection{Throughput Performance}

\begin{figure*}[ht]
  \centering
  \caption{Average Throughputs}
  \includegraphics[width=1.0\textwidth]{images/throughput}
\end{figure*}

\begin{table}[h]
\begin{tabular}{lll}
Average Throughput & SET Operation & GET Operation \\
Native & 37766.142 & 37792.576 \\
Host-to-Host & 26571.512 & 26348.028 \\
Mirage on Xen & 2188.18 & 2222.22 \\
Unix (500) & 3401.36 & 3787.88 \\
Unix (1000) & 3344.48 & 2024.29 \\
Unix (10000) & 580.55 & 338.26
\end{tabular}
\caption{Average throughputs (requests per second)}
\label{my-label}
\end{table}

Overall, the Mirage systems showed markedly worse throughput performance, at a staggering order of magnitude lower than the baseline Redis benchmarks.
Corrections to the Keyvee implementation are underway so that a fair benchmark comparison can be made and a provide a more representative view.

\section{Conclusion}
% @NATE
In the paper we have described the implementation and evaluation of our unikernel key-value store, Keyvee. Our efforts are concentrated around implementing a subset of Redis's functionality using OCaml and the Mirage OS toolchain. We then evaluate our implementation and compare it with Redis.


\section{Acknowledgements}
We thank the kind souls in the \#Mirage IRC chatroom for their relentless patience.
Their assistance was crucial in learning how to use Mirage's utilities and leverage the provided standard library.



\bibliographystyle{abbrv}
\bibliography{bibliography}


\end{document}



